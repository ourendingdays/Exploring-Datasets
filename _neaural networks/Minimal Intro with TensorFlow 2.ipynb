{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating Gradient Descent Algorithm with TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will simulate the following formula: 2*X -7*W + Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = 25000\n",
    "\n",
    "X = np.random.uniform(low = -10, high = 10, size = (observations, 1))\n",
    "W = np.random.uniform(low = -10, high = 10, size = (observations, 1))\n",
    "\n",
    "INPUTS = np.column_stack((X, W))\n",
    "\n",
    "noise = np.random.uniform(low = -1, high = 1, size = (observations, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-2.62299213],\n",
       "        [ 4.64955799],\n",
       "        [ 4.28726575],\n",
       "        ...,\n",
       "        [ 2.33593824],\n",
       "        [-3.0926153 ],\n",
       "        [ 3.29312211]]), (25000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 9.26464939],\n",
       "        [-5.94606681],\n",
       "        [ 2.30662044],\n",
       "        ...,\n",
       "        [ 6.36647994],\n",
       "        [ 0.52967216],\n",
       "        [-9.45511758]]), (25000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-2.62299213,  9.26464939],\n",
       "        [ 4.64955799, -5.94606681],\n",
       "        [ 4.28726575,  2.30662044],\n",
       "        ...,\n",
       "        [ 2.33593824,  6.36647994],\n",
       "        [-3.0926153 ,  0.52967216],\n",
       "        [ 3.29312211, -9.45511758]]), (25000, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUTS, INPUTS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.13851105],\n",
       "        [-0.06652155],\n",
       "        [ 0.27689163],\n",
       "        ...,\n",
       "        [-0.00527711],\n",
       "        [ 0.25470859],\n",
       "        [-0.58796814]]), (25000, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise, noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-60.23704107],\n",
       "       [ 60.85506211],\n",
       "       [  2.70508009],\n",
       "       ...,\n",
       "       [-29.8987602 ],\n",
       "       [  0.36177286],\n",
       "       [ 82.18409913]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGETS = 2*X - 7*W + 10 + noise\n",
    "TARGETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('TF_INTRO', inputs=INPUTS, targets=TARGETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('TF_INTRO.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables that measure the size of our inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <i>Sequential</i> specifies how the model will be laid down (stacked)\n",
    "\n",
    "\n",
    "2. <i>Dense</i> layer takes the inputs provided to the model and calculates the dot product of the inputs and the weights and adds bias. \n",
    "\n",
    "FROM TENSORFLOW DOCS: `Dense` implements the operation:\n",
    "`output = activation(dot(input, kernel) + bias)`\n",
    "where `activation` is the element-wise activation function\n",
    "passed as the `activation` argument, `kernel` is a weights matrix\n",
    "created by the layer, and `bias` is a bias vector created by the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8d9f2831d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(output_size)\n",
    "])\n",
    "\n",
    "# configuring the model for training\n",
    "model.compile(optimizer='SGD', loss='mean_squared_error')\n",
    "\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs = 100, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting <i>verbose = 0</i> makes the model \"silent\", thus no output is given\n",
    "\n",
    "Set <i>verbose</i> to \"2\" to obtain one-line-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 0s 20us/sample - loss: 0.3464\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3463\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3459\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3469\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3457\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 1s 28us/sample - loss: 0.3457\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3482\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3476\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3454\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3474\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3466\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3469\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 0s 20us/sample - loss: 0.3458\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.3457\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.3473\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 0s 20us/sample - loss: 0.3461\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3447\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3464\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3466\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3458\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3466\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3457\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3468\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3467\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3461\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3466\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3461\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3466\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3466\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3460\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3462\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3461\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3460\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3464\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.3452\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3461\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3458\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3467\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3467\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3464\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3462\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3472\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3473\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 1s 21us/sample - loss: 0.3448\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3477\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3472\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 1s 21us/sample - loss: 0.3443\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3460\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 1s 28us/sample - loss: 0.3454\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 1s 26us/sample - loss: 0.3454\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3468\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3453\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3463\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3471\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3458\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3475\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3458\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3464\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3446\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3467\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3460\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3463\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3462\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3458\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3456\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3465\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3447\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3462\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3467\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3454\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3465\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3463\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3471\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3458\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3446\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3475\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3462\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3465\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3465\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3456\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3450\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3462\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3462\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3457\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3463\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3461\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3460\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3457\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3467\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3463\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3468\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3476\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3461\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3445\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3456\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3463\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 1s 21us/sample - loss: 0.3457\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 1s 22us/sample - loss: 0.3453\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 0s 19us/sample - loss: 0.3458\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 0s 18us/sample - loss: 0.3462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8d9e6b6b10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data['inputs'], training_data['targets'], epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting weights and biases\n",
    "\n",
    "Output is a tensor with two arrays - one for the weights, one for the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.9937725],\n",
       "        [-7.0247025]], dtype=float32), array([10.006209], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It worked great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the outputs, making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.4158182 ],\n",
       "       [ 69.27829   ],\n",
       "       [  0.45665264],\n",
       "       ...,\n",
       "       [ 22.525946  ],\n",
       "       [ 21.836842  ],\n",
       "       [-48.28674   ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_on_batch(training_data['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.09531858],\n",
       "       [ 69.86728164],\n",
       "       [  1.26979627],\n",
       "       ...,\n",
       "       [ 23.57069651],\n",
       "       [ 21.64203904],\n",
       "       [-47.23952255]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 0s 292us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(training_data['inputs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "782/782 [==============================] - 0s 380us/step - loss: 19.4619\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 0s 347us/step - loss: 8.1281\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 0s 359us/step - loss: 6.5811\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 0s 348us/step - loss: 5.0436\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 0s 348us/step - loss: 3.5071\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 0s 349us/step - loss: 1.9735\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 0s 347us/step - loss: 0.6516\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 0s 349us/step - loss: 0.2131\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.1701\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 0s 367us/step - loss: 0.1677\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 0s 364us/step - loss: 0.1676\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 0s 355us/step - loss: 0.1676\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 0s 347us/step - loss: 0.1675\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 0s 405us/step - loss: 0.1675\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 0s 529us/step - loss: 0.1675\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 0s 431us/step - loss: 0.1676\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 0s 398us/step - loss: 0.1676\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 0s 431us/step - loss: 0.1675\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 0s 350us/step - loss: 0.1675\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 0s 408us/step - loss: 0.1676\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 0s 381us/step - loss: 0.1676\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 0s 407us/step - loss: 0.1675\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 0s 569us/step - loss: 0.1675\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 0s 395us/step - loss: 0.1676\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 0s 349us/step - loss: 0.1675\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 0s 494us/step - loss: 0.1676\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 0s 410us/step - loss: 0.1676\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 0s 353us/step - loss: 0.1676\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 0s 419us/step - loss: 0.1676\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 0s 415us/step - loss: 0.1676\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 0s 398us/step - loss: 0.1675\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 0s 410us/step - loss: 0.1675\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 0s 395us/step - loss: 0.1676\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 0s 391us/step - loss: 0.1675\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 0s 534us/step - loss: 0.1676\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 0s 376us/step - loss: 0.1675\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 0s 367us/step - loss: 0.1675\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 0s 531us/step - loss: 0.1676\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 0s 586us/step - loss: 0.1676\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 0s 424us/step - loss: 0.1676\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 0s 378us/step - loss: 0.1677\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 0s 361us/step - loss: 0.1676\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 0s 353us/step - loss: 0.1676\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 0s 350us/step - loss: 0.1675\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 0s 364us/step - loss: 0.1675\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 0s 365us/step - loss: 0.1676\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.1675\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 0s 389us/step - loss: 0.1676\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 0s 363us/step - loss: 0.1675\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 0s 354us/step - loss: 0.1676\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 0s 462us/step - loss: 0.1676\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 0s 406us/step - loss: 0.1676\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 0s 388us/step - loss: 0.1675\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 0s 375us/step - loss: 0.1675\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 0s 347us/step - loss: 0.1676\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 0s 354us/step - loss: 0.1676\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 0s 374us/step - loss: 0.1676\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 0s 384us/step - loss: 0.1676\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 0s 383us/step - loss: 0.1675\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 0s 350us/step - loss: 0.1677\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 0s 351us/step - loss: 0.1676\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 0s 344us/step - loss: 0.1675\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 0s 349us/step - loss: 0.1676\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 0s 347us/step - loss: 0.1676\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 0s 350us/step - loss: 0.1675\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 0s 343us/step - loss: 0.1676\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 0s 345us/step - loss: 0.1675\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 0s 351us/step - loss: 0.1675\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 0s 346us/step - loss: 0.1675\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 0s 349us/step - loss: 0.1675\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 0s 365us/step - loss: 0.1675\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 0s 356us/step - loss: 0.1676\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 0s 360us/step - loss: 0.1676\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 0s 375us/step - loss: 0.1675\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 0s 343us/step - loss: 0.1675\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 0s 351us/step - loss: 0.1675\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 0s 344us/step - loss: 0.1676\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 0s 349us/step - loss: 0.1676\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 0s 346us/step - loss: 0.1676\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 0s 345us/step - loss: 0.1676\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 0s 347us/step - loss: 0.1677\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 0s 346us/step - loss: 0.1676\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 0s 350us/step - loss: 0.1676\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 0s 344us/step - loss: 0.1676\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 0s 349us/step - loss: 0.1676\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 0s 349us/step - loss: 0.1676\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 0s 348us/step - loss: 0.1676\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 0s 345us/step - loss: 0.1676\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 0s 345us/step - loss: 0.1676\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 0s 346us/step - loss: 0.1676\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 0s 348us/step - loss: 0.1676\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 0s 353us/step - loss: 0.1676\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 0s 347us/step - loss: 0.1675\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 0s 345us/step - loss: 0.1676\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 0s 344us/step - loss: 0.1676\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 0s 344us/step - loss: 0.1675\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 0s 340us/step - loss: 0.1676\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 0s 337us/step - loss: 0.1676\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 0s 342us/step - loss: 0.1675\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 0s 341us/step - loss: 0.1676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb2ddf04a90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ctd = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(output_size, kernel_initializer = tf.random_uniform_initializer(-0.1, 0.1),\n",
    "                         bias_initializer = tf.random_uniform_initializer(-0.1, 0.1))\n",
    "])\n",
    "\n",
    "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.002)\n",
    "\n",
    "model_ctd.compile(optimizer=custom_optimizer, loss='huber_loss')\n",
    "\n",
    "model_ctd.fit(training_data['inputs'], training_data['targets'], epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.9937725],\n",
       "        [-7.0247025]], dtype=float32), array([10.006209], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss is much smaller!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
